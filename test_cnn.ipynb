{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-9o5GKG8S8G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2N72wzhjbxdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install image-classifiers==0.2.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0pDoNXOXdEV",
        "outputId": "e79c108c-f9c3-461a-934e-e9e07d2ff76c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting image-classifiers==0.2.2\n",
            "  Downloading image_classifiers-0.2.2-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from image-classifiers==0.2.2) (2.8.0)\n",
            "Installing collected packages: image-classifiers\n",
            "Successfully installed image-classifiers-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfKUnwtqXgvg",
        "outputId": "9c3e2053-22d8-468d-8710-f231a04d2119"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/qubvel/classification_models.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnUc446pXpDj",
        "outputId": "0ae67c90-fdf2-4b32-f8e4-97e5f8c0f3e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/qubvel/classification_models.git\n",
            "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-1mdfezul\n",
            "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-1mdfezul\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Collecting keras_applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.21.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.5.2)\n",
            "Building wheels for collected packages: image-classifiers\n",
            "  Building wheel for image-classifiers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20046 sha256=0add090924dc9b37fab82537e6d26173249f2114a36d8c03dc2e057a40c69141\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6w2ucfs_/wheels/0b/96/56/27b17c903efc647c51e4f364bfc20aa67f8d3dccad63c4fb4e\n",
            "Successfully built image-classifiers\n",
            "Installing collected packages: keras-applications, image-classifiers\n",
            "  Attempting uninstall: image-classifiers\n",
            "    Found existing installation: image-classifiers 0.2.2\n",
            "    Uninstalling image-classifiers-0.2.2:\n",
            "      Successfully uninstalled image-classifiers-0.2.2\n",
            "Successfully installed image-classifiers-1.0.0 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u-3tLqNXZr7l",
        "outputId": "9ba49736-71c8-4865-9f09-54fe82bc52e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.34.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.1.0) (0.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.1.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=7a115bab5d80cdbb5639dbdff0bc9ad9654934f9a85c2ab729fcd8dc991c1d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.5.3\n",
            "    Uninstalling tensorflow-2.5.3:\n",
            "      Successfully uninstalled tensorflow-2.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "keras 2.4.0 requires tensorflow>=2.2.0, but you have tensorflow 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from glob import glob\n",
        "from tqdm import notebook\n",
        "from sklearn import preprocessing\n",
        "from keras import Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras import optimizers\n",
        "import keras\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import sys, os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import load_model\n",
        "from keras.models import model_from_json\n",
        "import h5py"
      ],
      "metadata": {
        "id": "mKhD-sTQ8doG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tcuQfGNQWasv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "Opening Data \n",
        "***"
      ],
      "metadata": {
        "id": "VaP4defG8qSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hiZOxMYdTtGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a957a35e-4cfb-4e0e-e19b-565a11905292"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = '/content/drive/My Drive/datachallenge/data_train_images.h5'"
      ],
      "metadata": {
        "id": "l7IoiXHuRmdI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5f = h5py.File(train,'r')\n",
        "train_images = h5f['data_train_images'][:]\n",
        "h5f.close()\n"
      ],
      "metadata": {
        "id": "F0BX-Fi_UaqD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5f = h5py.File('/content/drive/My Drive/datachallenge/data_train_labels.h5','r')\n",
        "train_labels = h5f['data_train_labels'][:]\n",
        "h5f.close()"
      ],
      "metadata": {
        "id": "xVIXybS-i0Pi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h5f = h5py.File('/content/drive/My Drive/datachallenge/data_test_images.h5','r')\n",
        "test_images = h5f['data_test_images'][:]\n",
        "h5f.close()\n"
      ],
      "metadata": {
        "id": "FrXVXAFXW4Nu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "2D CNN\n",
        "***"
      ],
      "metadata": {
        "id": "XVdPEPeCZAFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 6\n"
      ],
      "metadata": {
        "id": "UxziI6KkjRCM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using only the last image\n",
        "train_1 = train_images[:, 0, :,:].copy()\n",
        "train_9 = train_images[:, -1, :,:].copy()\n",
        "train_5 = train_images[:, 5, :,:].copy()"
      ],
      "metadata": {
        "id": "Uq_ivpLsgRWn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using only the last image\n",
        "test_1 = test_images[:, 0, :,:].copy()\n",
        "test_9 = test_images[:, -1, :,:].copy()\n",
        "test_5 = test_images[:, 5, :,:].copy()"
      ],
      "metadata": {
        "id": "4BTxtsz0UHW_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove uncessary dimensions\n",
        "train_1 = np.squeeze(train_1)\n",
        "train_9 = np.squeeze(train_9)\n",
        "train_5 = np.squeeze(train_5)\n",
        "\n",
        "\n",
        "#set three new channels to pass through network\n",
        "img2 = np.zeros( (train_1.shape[0], train_1.shape[1],train_1.shape[2], 3 ) )\n",
        "\n",
        "img2[:,:,:,0] = train_1\n",
        "img2[:,:,:,1] = train_5\n",
        "img2[:,:,:,2] = train_9\n",
        "\n"
      ],
      "metadata": {
        "id": "KWsiledPki2v"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove uncessary dimensions\n",
        "test_1 = np.squeeze(test_1)\n",
        "test_9 = np.squeeze(test_9)\n",
        "test_5 = np.squeeze(test_5)\n",
        "\n",
        "\n",
        "#set three new channels to pass through network\n",
        "X_test = np.zeros( (test_1.shape[0], test_1.shape[1],test_1.shape[2], 3 ) )\n",
        "\n",
        "X_test[:,:,:,0] = test_1\n",
        "X_test[:,:,:,1] = test_5\n",
        "X_test[:,:,:,2] = test_9"
      ],
      "metadata": {
        "id": "rDL4S0tDUWdO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from classification_models.keras import Classifiers\n",
        "\n",
        "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
        "\n"
      ],
      "metadata": {
        "id": "3K0U1fl8Vwpg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "base_model = ResNet18(input_shape=(300,200,3), include_top=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "model = keras.models.Model(inputs=[base_model.input], outputs=[output])"
      ],
      "metadata": {
        "id": "agMzYA40gwzN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "UYgPIOKCp5QZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding labels\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(train_labels.reshape(540,1))\n",
        "lala =enc.transform(train_labels.reshape(540,1)).toarray()"
      ],
      "metadata": {
        "id": "9L4hDLAIqEtR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "model.compile(optimizer='ADAM', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(img2, lala)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ZaL225mTUq",
        "outputId": "f93b6451-296f-4b9e-f542-cf66fad27361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/17 [=========================>....] - ETA: 21s - loss: 1.9295 - accuracy: 0.2833"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(img2[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ-0Gw-Koa9W",
        "outputId": "ebd8a8bf-6b00-494a-a855-f55d0cef8cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7ef2a34d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.31069118, 0.11901982, 0.04378638, 0.18980035, 0.02723224,\n",
              "        0.3094701 ],\n",
              "       [0.25729915, 0.08089131, 0.11043912, 0.12252928, 0.09160694,\n",
              "        0.33723423],\n",
              "       [0.18785498, 0.05700729, 0.1779961 , 0.10630246, 0.03545982,\n",
              "        0.4353794 ],\n",
              "       [0.30436468, 0.05623237, 0.11653003, 0.08759913, 0.0576108 ,\n",
              "        0.377663  ],\n",
              "       [0.25337547, 0.09316412, 0.06554199, 0.10797251, 0.04835999,\n",
              "        0.43158594],\n",
              "       [0.12961671, 0.14684701, 0.20796438, 0.09396657, 0.02925717,\n",
              "        0.39234814],\n",
              "       [0.1755538 , 0.07780797, 0.09107749, 0.07147866, 0.02202848,\n",
              "        0.56205356],\n",
              "       [0.22693352, 0.1071989 , 0.09538312, 0.08642829, 0.05691462,\n",
              "        0.4271415 ],\n",
              "       [0.1537007 , 0.1031141 , 0.242102  , 0.07339077, 0.03396565,\n",
              "        0.39372677],\n",
              "       [0.33190128, 0.07076675, 0.16669321, 0.08148702, 0.04625211,\n",
              "        0.3028996 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    }
  ]
}